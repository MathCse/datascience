{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\def\\*#1{\\mathbf{#1}}$\n",
    "$\\DeclareMathOperator*{\\argmax}{arg\\,max}$\n",
    "# Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# pyplot : Provides a MATLAB-like plotting framework\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# %matplotlib notebook\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Matrix\n",
    "\n",
    "The data set is represented by a $n \\times d$ **data matrix** :\n",
    "\n",
    "$$\n",
    "D = \n",
    "\\begin{pmatrix}\n",
    "  x_{1,1} & x_{1,2} & \\cdots & x_{1,d} \\\\\n",
    "  x_{2,1} & x_{2,2} & \\cdots & x_{2,d} \\\\\n",
    "  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "  x_{n,1} & x_{n,2} & \\cdots & x_{n,d} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "* The *i*-th **row** refers, depending on the application, to an *entity*, *instance*, **record**, *transaction*, *alternative*,...\n",
    "\n",
    "$$\\*x_i = (x_{i1}, x_{i1}, \\ldots, x_{id})$$\n",
    "\n",
    "* The *j*-th **column** refers to an *attribute*, **feature**, *dimension*, *criteria*,... \n",
    "\n",
    "$$X_j = (x_{1j}, x_{2j}, \\ldots, x_{nj})$$\n",
    "\n",
    "$$\n",
    "D = \n",
    "\\left(\n",
    "\\begin{array}{c|cccc}\n",
    "        & X_1 & X_2 & \\cdots & X_d\\\\\n",
    "        \\hline\n",
    "  \\*x_1 & x_{1,1} & x_{1,2} & \\cdots & x_{1,d} \\\\\n",
    "  \\*x_2 & x_{2,1} & x_{2,2} & \\cdots & x_{2,d} \\\\\n",
    "  \\vdots & \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "  \\*x_n & x_{n,1} & x_{n,2} & \\cdots & x_{n,d} \n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Data Set\n",
    "\n",
    " | sepal length (cm) | sepal width (cm) | petal length (cm) | petal width (cm) | Type of iris plant |\n",
    " | ----------------- | ---------------- | ----------------- | ---------------- | ------------------ |\n",
    " | 5.1               | 3.5              | 1.4               | 0.2              | Setosa             |\n",
    " | 4.8               | 3.0              | 1.4               | 0.3              | Setosa             |\n",
    " | 6.0               | 3.4              | 4.5               | 1.6              | Versicolor         |\n",
    " | 6.8               | 3.0              | 5.5               | 2.1              | Virginica          |\n",
    " | 6.7               | 3.1              | 5.6               | 2.4              | Virginica          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = '../datasets/iris.data'\n",
    "\n",
    "classes = {b'Iris-setosa': 0, b'Iris-versicolor': 1, b'Iris-virginica': 2}\n",
    "\n",
    "classes_converter = {4: lambda c: classes[c]}\n",
    "\n",
    "data = np.loadtxt(filename, delimiter=',', skiprows=1, converters=classes_converter)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "xi = data[i]\n",
    "print(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "Xj = data[:,j]\n",
    "print(Xj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xj = data[0:5,j]\n",
    "print(Xj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('../datasets/iris.data')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "xi = df.iloc[i]\n",
    "print(xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "\n",
    "* Numeric attributes\n",
    "\n",
    "* Categorical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric (quantitative) Attributes\n",
    "\n",
    "* `domain(age)` = $\\mathbb{N}$\n",
    "* `domain(petal length)` = $\\mathbb{R}_{>0}$\n",
    "* **discrete** : finite or countably infinite set of values\n",
    "* **continuous** : any real value\n",
    "\n",
    "**Measurement scales**\n",
    "\n",
    "* **Interval scale** :\n",
    "    * Only addition and substration make sense. \n",
    "    * The *zero point* does not indicate the absence of measurement. \n",
    "    * The `temperature` measured in $^{\\circ}C$ is interval-scaled. If two measurements of $20 ^{\\circ}C$ and $10 ^{\\circ}C$ are compared, what is the right statement ?\n",
    "        * There is a temperature drop of $10 ^{\\circ}C$.\n",
    "        * The second measure is twice as cold as the first one.\n",
    "* **Ratio scale**\n",
    "    * Addition, substraction, and ratio make sense.\n",
    "    * The `Age` attribute is ratio-scaled.\n",
    "    * The `temperature` mesured in *Kelvin* is ratio-scaled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical (qualitative) Attributes\n",
    "* A set of symbols, for example : \n",
    "    * `domain(Education) = {HighSchool, BS, MS, PhD}`\n",
    "    * `domain(Fruits) = {Orange, Apple}`\n",
    "\n",
    "**Measurement scales**\n",
    "\n",
    "* **Nominal scale** : values are *unordered* \n",
    "* **Ordinal scale** : values are *ordered* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel('Sepal length')\n",
    "ax.set_ylabel('Sepal width')\n",
    "\n",
    "X = data[:,0:4]\n",
    "Y = data[:,4]\n",
    "\n",
    "ax.scatter(X[:, 0], X[:, 1], c=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4)\n",
    "attributes = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "for i in range(4):\n",
    "    axs[i, 0].set_ylabel(attributes[i])\n",
    "    axs[-1, i].set_xlabel(attributes[i])\n",
    "    for j in range(4):\n",
    "        axs[i, j].scatter(X[:, i], X[:, j], c=Y)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "n, bins, patches = ax.hist(X[:,0], bins=10, edgecolor='black', linewidth=1)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel(attributes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "hist = ax.hist([1,1,1,2,2,4,4], bins=3, edgecolor='black', linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency-oriented data\n",
    "\n",
    "Relationships between data items :\n",
    "\n",
    "* **Time-Series** : data generated by continouous measurement over time\n",
    "    * *environmental sensor* : temperature, pressure\n",
    "    * *finantial market analysis*\n",
    "* **Discrete Sequences**\n",
    "    * *event logs* such as web accesses : Client IP, Web page address\n",
    "    * *strings*\n",
    "* **Spatial** : non-spatial attributes measured at spatial locations\n",
    "    * *hurricane forecasting* : sea-surface temperature, pressure\n",
    "* **Spatiotemporal**\n",
    "* **Network and Graph Data**\n",
    "    * *Web graph*\n",
    "    * *Social networks*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data\n",
    "\n",
    "* A **string** : a discrete sequence of characters\n",
    "* **Vector-space representation** : words (terms) frequencies (normalized with respect to the document length)\n",
    "    * **Document-term matrix** : $n$ documents $\\times$ $d$ terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scikit-learn : Machine Learning in Python\n",
    "\n",
    "# See : http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "# and and http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# CountVectorizer : Convert a collection of text documents to a matrix of token counts\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "corpus = ['This is the first document.',\n",
    "          'This is the second second document.',\n",
    "          'And the third one.',\n",
    "          'Is this the first document?']\n",
    "\n",
    "# Learn the vocabulary dictionary and return term-document matrix.\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph $G = (V, E)$ with $n$ ***vertices*** and $m$ ***edges*** consists of:\n",
    "\n",
    "* $V = V(G)$ : a vertex set; $n = |V|$ is the order of $G$\n",
    "* $E = E(G)$ : a set of pairs of vertices, called edges; $m = |E|$\n",
    "\n",
    "A ***weighted graph*** is a graph $G = (V, E)$ in which each edge $e \\in E(G)$ is given a numerical weight $w(e)$, where $w : E \\rightarrow \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "    \n",
    "def draw_weighted_graph(g):\n",
    "    pos = nx.spectral_layout(g)\n",
    "    nx.draw_networkx(g, pos)\n",
    "    edge_labels = {edge[0:2]: edge[2]['weight'] for edge in g.edges(data=True)}\n",
    "    nx.draw_networkx_edge_labels(g, pos, edge_labels)\n",
    "\n",
    "g = nx.Graph()\n",
    "    \n",
    "g.add_nodes_from(['Lille', 'Paris', 'Amiens', 'Arras'])\n",
    "g.add_edge('Lille', 'Paris', weight=225)\n",
    "g.add_edge('Lille', 'Amiens', weight=62.7)\n",
    "g.add_edge('Lille', 'Arras', weight=52.7)\n",
    "g.add_edge('Paris', 'Amiens', weight=144.4)\n",
    "g.add_edge('Paris', 'Arras', weight=185.8)\n",
    "g.add_edge('Amiens', 'Arras', weight=62.6)\n",
    "\n",
    "draw_weighted_graph(g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
